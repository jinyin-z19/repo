{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([78.79561882, 45.16050481])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WW9\n",
    "import numpy as np            \n",
    "c=np.random.random((3,3))  #随机数组\n",
    "d=np.random.normal((2,3,4)) #正态填充\n",
    "\n",
    "x=np.array([22,35,86])\n",
    "e=np.random.random((3,3))\n",
    "f=np.random.random((2,3))\n",
    "\n",
    "g=np.dot(f,np.dot(e,x))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]], shape=(3, 2), dtype=float16)\n",
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1. 2. 3. 4.]\n",
      " [3. 6. 5. 4.]\n",
      " [5. 1. 1. 6.]\n",
      " [5. 2. 1. 6.]], shape=(4, 4), dtype=float16)\n",
      "tf.Tensor(\n",
      "[[[0.91956422 0.51420332 0.81434512 0.16542258 0.73641151 0.34706702]\n",
      "  [0.39856715 0.66200714 0.3681809  0.12766217 0.34876338 0.89603086]\n",
      "  [0.2913651  0.85567377 0.40124515 0.64259314 0.74945145 0.6534142 ]\n",
      "  [0.65792284 0.76653899 0.30165342 0.52839438 0.96335933 0.05885485]\n",
      "  [0.74396234 0.79620795 0.65717883 0.99326185 0.96540287 0.36061807]]\n",
      "\n",
      " [[0.99048903 0.72444131 0.01885874 0.10977322 0.2071735  0.8592011 ]\n",
      "  [0.34481617 0.70191059 0.40209782 0.90762198 0.55704329 0.46202588]\n",
      "  [0.50055939 0.38989016 0.65147021 0.78419715 0.41927644 0.1378639 ]\n",
      "  [0.06542924 0.94970692 0.67602808 0.53190972 0.94885942 0.8297273 ]\n",
      "  [0.52047127 0.36854887 0.07179187 0.82801223 0.88404842 0.33444296]]\n",
      "\n",
      " [[0.85823541 0.31685117 0.95462617 0.88038371 0.80614865 0.55548848]\n",
      "  [0.94251491 0.60962863 0.3307893  0.30544088 0.25075623 0.04135161]\n",
      "  [0.57781108 0.88049065 0.28813168 0.6668039  0.75111726 0.21868316]\n",
      "  [0.4622283  0.23732442 0.99520135 0.85979875 0.66900193 0.26247504]\n",
      "  [0.19833755 0.54458717 0.49003326 0.44204642 0.25532137 0.4116454 ]]\n",
      "\n",
      " [[0.91554288 0.24303247 0.33745931 0.39202566 0.76655801 0.29174868]\n",
      "  [0.80124983 0.17334234 0.11010201 0.82281999 0.87826592 0.06453197]\n",
      "  [0.42926185 0.37267343 0.57865751 0.45896469 0.69179017 0.34402448]\n",
      "  [0.87812715 0.62070138 0.92893891 0.19649928 0.92427818 0.07049779]\n",
      "  [0.60938671 0.48655529 0.53074931 0.45764319 0.47123702 0.47241703]]], shape=(4, 5, 6), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105860e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np    \n",
    "print(tf.__version__)\n",
    "a=tf.constant(1.0)\n",
    "b=tf.constant(2.0)\n",
    "c=a+b\n",
    "print(c)\n",
    "\n",
    "\n",
    "rank_0_tensor = tf.constant(4)\n",
    "print(rank_0_tensor)\n",
    "\n",
    "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])#三维向量\n",
    "print(rank_1_tensor)\n",
    "\n",
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(rank_2_tensor)\n",
    "\n",
    "rank_3_tensor = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])\n",
    "                    \n",
    "print(rank_3_tensor)\n",
    "\n",
    "#4*4\n",
    "my44tensor = tf.constant([[1,2,3,4],\n",
    "                             [3,6,5,4],\n",
    "                             [5,1,1,6],\n",
    "                             [5,2,1,6]], dtype=tf.float16)\n",
    "print(my44tensor)\n",
    "#4*5*6利用numpy创建数组\n",
    "my456tensor = tf.constant(np.random.random([4,5,6]))\n",
    "print(my456tensor)\n",
    "\n",
    "# 运算\n",
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
    "\n",
    "print(tf.add(a, b), \"\\n\")\n",
    "print(tf.multiply(a, b), \"\\n\")\n",
    "print(tf.matmul(a, b), \"\\n\")\n",
    "\n",
    "#一些函数\n",
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# Find the largest value\n",
    "print(tf.reduce_max(c))\n",
    "# Find the index of the largest value\n",
    "print(tf.argmax(c))\n",
    "# Compute the softmax\n",
    "print(tf.nn.softmax(c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  2  3  5  8 13 21 34]\n",
      "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
      "Before 4: [0 1 1 2]\n",
      "From 4 to the end: [ 3  5  8 13 21 34]\n",
      "From 2, before 7: [1 2 3 5 8]\n",
      "Every other item: [ 0  1  3  8 21]\n",
      "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
     ]
    }
   ],
   "source": [
    "# 单轴切片\n",
    "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
    "print(rank_1_tensor.numpy())\n",
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n",
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
    "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second row: [3. 4.]\n",
      "Second column: [2. 4. 6.]\n",
      "Last row: [5. 6.]\n",
      "First item in last column: 2.0\n",
      "Skip the first row:\n",
      "[[3. 4.]\n",
      " [5. 6.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#多轴切片\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# reshape\n",
    "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
    "print(tf.reshape(rank_3_tensor, [3, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2, 2)\n",
      "DType:  <dtype: 'float32'>\n",
      "As NumPy:  <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>>\n",
      "\n",
      "Copying and reshaping:  tf.Tensor([[1. 2. 3. 4.]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#变量\n",
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "my_variable = tf.Variable(my_tensor)\n",
    "\n",
    "bool_variable = tf.Variable([False, False, False, True])\n",
    "complex_variable = tf.Variable([5 + 4j, 6 + 1j])\n",
    "print(\"Shape: \",my_variable.shape)\n",
    "print(\"DType: \",my_variable.dtype)\n",
    "print(\"As NumPy: \", my_variable.numpy)\n",
    "print(\"\\nCopying and reshaping: \", tf.reshape(my_variable, ([1,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 6.]\n",
      "[2. 3.]\n",
      "[7. 9.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "# Create b based on the value of a\n",
    "b = tf.Variable(a)\n",
    "a.assign([5, 6])\n",
    "\n",
    "# a and b are different\n",
    "print(a.numpy())\n",
    "print(b.numpy())\n",
    "\n",
    "# There are other versions of assign\n",
    "print(a.assign_add([2,3]).numpy())  # [7. 9.]\n",
    "print(a.assign_sub([7,9]).numpy())  # [0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.7182817, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#自动微分\n",
    "x=tf.constant(1.0)\n",
    "\n",
    "with tf.GradientTape() as t:   #磁带\n",
    "    t.watch(x)\n",
    "    y = tf.multiply(x, x)+tf.exp(x)\n",
    "dy_dx = t.gradient(y, x)\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "FizzBuzz\n"
     ]
    }
   ],
   "source": [
    "#即可执行\n",
    "def fizzbuzz(max_num):\n",
    "    counter = tf.constant(0)\n",
    "    max_num = tf.convert_to_tensor(max_num)\n",
    "    for num in range(1, max_num.numpy()+1):\n",
    "        num = tf.constant(num)\n",
    "        if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "            print('FizzBuzz')\n",
    "        elif int(num % 3) == 0:\n",
    "            print('Fizz')\n",
    "        elif int(num % 5) == 0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num.numpy())\n",
    "        counter += 1\n",
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
